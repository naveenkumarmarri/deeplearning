{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 part 2 - Speech enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting configurations for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, sr=librosa.load('train_clean_male.wav', sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "sn, sr=librosa.load('train_dirty_male.wav', sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_abs = np.abs(S)\n",
    "X_abs = np.abs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 2459)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_abs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the test signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t_1, sr_1=librosa.load('test_x_01.wav', sr=None)\n",
    "X_test_1=librosa.stft(s_t_1, n_fft=1024, hop_length=512)\n",
    "s_t_2, sr_2=librosa.load('test_x_02.wav', sr=None)\n",
    "X_test_2=librosa.stft(s_t_2, n_fft=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 513])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 513])\n",
    "rate = tf.placeholder(tf.float32)\n",
    "num_nodes_1 = 1000\n",
    "num_nodes_2 = 1024\n",
    "num_nodes_3 = 1024\n",
    "num_nodes_4 = 1024\n",
    "learning_rate = 0.001\n",
    "# kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "#                                           bias_initializer=tf.keras.initializers.he_normal(),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.061181895for epoch 0\n",
      "Accuracy is 0.0049223015for epoch 100\n",
      "Accuracy is 0.0026222828for epoch 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_layer = tf.layers.dense(X, num_nodes_1, kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                               bias_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                             activation = tf.nn.relu)\n",
    "# drop_1 = tf.layers.dropout(first_layer,rate = rate)\n",
    "second_layer = tf.layers.dense(first_layer, num_nodes_1, kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                               bias_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                              activation = tf.nn.relu)\n",
    "# drop_2 = tf.layers.dropout(second_layer,rate = rate)\n",
    "# third_layer = tf.layers.dense(drop_2, num_nodes_3, kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "#                                           bias_initializer=tf.keras.initializers.glorot_normal(),\n",
    "#                               activation = tf.nn.tanh)\n",
    "# drop_3 = tf.layers.dropout(third_layer,rate = rate)\n",
    "third_layer = tf.layers.dense(second_layer, num_nodes_1,kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                              bias_initializer = tf.keras.initializers.glorot_normal(),\n",
    "                              activation = tf.nn.relu)\n",
    "\n",
    "# drop_4 = tf.layers.dropout(encoded,rate =rate)\n",
    "# third_layer_1 = tf.layers.dense(drop_4, num_nodes_3,  kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "#                                           bias_initializer=tf.keras.initializers.glorot_normal(),\n",
    "#                               activation = tf.nn.tanh)\n",
    "\n",
    "# drop_5 = tf.layers.dropout(third_layer_1,rate =rate)\n",
    "fourth_layer = tf.layers.dense(third_layer, num_nodes_1,  kernel_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                                          bias_initializer=tf.keras.initializers.glorot_normal(),\n",
    "                              activation = tf.nn.relu)\n",
    "# drop_6 = tf.layers.dropout(second_layer_1,rate =rate)\n",
    "# first_layer_1 = tf.layers.dense(second_layer_1, 700,  kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "# #                                           bias_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "#                               activation = tf.nn.tanh)\n",
    "# drop_7 = tf.layers.dropout(first_layer_1,rate =rate)\n",
    "decoded =  tf.layers.dense(fourth_layer, 513,  kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           bias_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                              activation = tf.nn.relu)\n",
    "\n",
    "# logits = tf.layers.dense(decoded, Y.shape[1], activation=tf.nn.tanh)\n",
    "\n",
    "# prediction = tf.nn.softmax(logits)\n",
    "\n",
    "loss_op = tf.losses.mean_squared_error(labels = Y,\n",
    "                            predictions = decoded)\n",
    "# loss_op = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "#                                          labels = Y)\n",
    "# loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "#     logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "# correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# accuracy = tf.sqrt(tf.reduce_mean(loss_op))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_size = 64\n",
    "    \n",
    "    for epoch in range(0, 300):\n",
    "        accuracy_temp = []\n",
    "        for i in range(0, X_abs.shape[1]+1, batch_size):\n",
    "            X_batch = X_abs.T[i:i+batch_size]\n",
    "            Y_batch = S_abs.T[i:i+batch_size]\n",
    "            accuracy_, _ = sess.run([ loss_op, train_op], feed_dict={X:X_batch, \n",
    "                                                          Y:Y_batch,\n",
    "                                                          rate:0.10})\n",
    "            accuracy_temp.append(accuracy_)\n",
    "        accuracy_ = np.array(accuracy_temp).mean()\n",
    "#         print(str(accuracy_) + 'for epoch '+str(epoch))\n",
    "        accuracy_temp = []\n",
    "        if epoch % 100 == 0:\n",
    "            print('Accuracy is '+str(accuracy_) + 'for epoch '+str(epoch))\n",
    "    output_test_1 = sess.run(decoded, feed_dict={X:np.abs(X_test_1).T,\n",
    "                                                 rate:0.0})\n",
    "    output_test_2 = sess.run(decoded, feed_dict={X:np.abs(X_test_2).T,\n",
    "                                                 rate:0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for displaying the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavPlayer(filepath):\n",
    "    src = \"\"\"\n",
    "    <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">   \n",
    "    <body>\n",
    "    <audio controls=\"controls\" style=\"width:600px\" >\n",
    "      <source src=\"files/%s\" type=\"audio/wav\" />\n",
    "    </audio>\n",
    "    </body>\n",
    "    \"\"\"%(filepath)\n",
    "    display(HTML(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_phase = X_test_1 / np.abs(X_test_1)\n",
    "out = np.multiply(X_test_phase, output_test_1.T)\n",
    "y_hat = librosa.istft(out,  hop_length=512)\n",
    "y_1 = librosa.istft(X_test_1,  hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.output.write_wav('test_s_01_recons.wav', y_hat, sr_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing the reconstructed test signal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <head>\n",
       "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">   \n",
       "    <body>\n",
       "    <audio controls=\"controls\" style=\"width:600px\" >\n",
       "      <source src=\"files/test_s_01_recons.wav\" type=\"audio/wav\" />\n",
       "    </audio>\n",
       "    </body>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wavPlayer(\"test_s_01_recons.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_phase = X_test_2 / np.abs(X_test_2)\n",
    "out = np.multiply(X_test_phase, output_test_2.T)\n",
    "y_hat = librosa.istft(out,  hop_length=512)\n",
    "y_2 = librosa.istft(X_test_2,  hop_length=512)\n",
    "librosa.output.write_wav('test_s_02_recons.wav', y_hat, sr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing the reconstructed test signal 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <head>\n",
       "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">   \n",
       "    <body>\n",
       "    <audio controls=\"controls\" style=\"width:600px\" >\n",
       "      <source src=\"files/test_s_02_recons.wav\" type=\"audio/wav\" />\n",
       "    </audio>\n",
       "    </body>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wavPlayer(\"test_s_02_recons.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
